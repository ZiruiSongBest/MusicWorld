# Music Generation
Copet, Jade, et al. "Simple and controllable music generation." Advances in Neural Information Processing Systems 36 (2024).   

Huang, Rongjie, et al. "Audiogpt: Understanding and generating speech, music, sound, and talking head." Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 38. No. 21. 2024.  

Huang, Qingqing, et al. "Noise2music: Text-conditioned music generation with diffusion models." arXiv preprint arXiv:2302.03917 (2023).   

Hassid, Michael, et al. "Textually pretrained speech language models." Advances in Neural Information Processing Systems 36 (2024).  

Tang, Changli, et al. "Salmonn: Towards generic hearing abilities for large language models." arXiv preprint arXiv:2310.13289 (2023).  

Lam, Max WY, et al. "Efficient neural music generation." Advances in Neural Information Processing Systems 36 (2024).

# Audio to Text (Speech emotion recognition)
## database
RAVDESS: A multi-emotional, multi-language audio dataset containing speech and video in different emotional states.

IEMOCAP: Contains dialogue data of actors in different emotional scenes, and is one of the most commonly used datasets in SER research.

EmoDB: A German emotional speech database, often used for the evaluation of emotion recognition models.
## Existing APIS
https://www.assemblyai.com/
AssemblyAI API not only converts speech to text but also analyzes audio to detect and recognize emotions within the speech.







# Vision Language Model( Image Information Extraction)
Caption  
LLaVA  
Video-Llama  
API (zhipu)  

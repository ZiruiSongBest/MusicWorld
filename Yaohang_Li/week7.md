This week, I explored some newly released multi-modal language model. Due to very vague information from previously chosen model, I explored some LLM with audio capabilities.

- [GAMA](https://arxiv.org/abs/2406.11768) is a multimodal large language model with audio understanding capabilities. With help of language model, we can integrate audio and text in a unified framework.
- [LLaMA-Omni](https://github.com/ictnlp/LLaMA-Omni) As GPT-4o showed great capability in multi-modal understanding, the newly released LLaMA-Omni is expected to have similar capabilities.

Besides these, I prepared for the presentation to other groups for the class.